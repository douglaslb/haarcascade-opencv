{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#caminho onde estão os pesos\n",
    "face_classifier = cv2.CascadeClassifier('cascade/haarcascade_frontalface_default.xml') \n",
    "eyes_classifier = cv2.CascadeClassifier('cascade/haarcascade_mcs_eyepair_big.xml') "
   ]
  },
  {
   "source": [
    " ## **R1 - NOTA 6**\n",
    "\n",
    "Faz detecção de face em tempo real em vídeo ou webcam. Como resultado deve ter 2 janelas. A primeira janela com a imagem original e a segunda com a filtragem apenas na área da face.\n",
    "Opções de filtros para aplicar na área da face:\n",
    "- Filtro linear como filtro de borramento E/OU filtro de realce E/OU filtro de contorno E/OU qualquer outro filtro de sua escolha. \n",
    "Note que é necessário aplicar pelo menos uma das técnicas de filtragem em um vídeo e apenas na área da face. Implementações extras, valem como nota extra..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_filter(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces_return = face_classifier.detectMultiScale(img_gray, scaleFactor = 1.2, minNeighbors = 5)\n",
    "    if len(faces_return) != 0:     \n",
    "         for (x,y,w,h) in faces_return:\n",
    "            face_area = img[y:y+h, x:x+w]\n",
    "\n",
    "            ##Aplica filtro linear de blur e medianBlur\n",
    "            img[y:y+h, x:x+w] = cv2.blur(face_area, (80, 80))\n",
    "            img[y:y+h, x:x+w] = cv2.medianBlur(face_area, 25)\n",
    "\n",
    "            ##Aplica filtro de contorno\n",
    "            thresh = cv2.adaptiveThreshold(img_gray[y:y+h, x:x+w],255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,23,3)\n",
    "            cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "            for c in cnts:\n",
    "                area = cv2.contourArea(c)\n",
    "                if area > 10:\n",
    "                    cv2.drawContours(img[y:y+h, x:x+w], [c], -1, (36,255,12), 1)\n",
    "\n",
    "         return img\n",
    "    else:\n",
    "       return img\n",
    "\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): \n",
    "    rval, frame = vc.read()\n",
    "\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"original\", frame)\n",
    "\n",
    "    img = linear_filter(frame)\n",
    "    cv2.imshow(\"preview\", img)\n",
    "\n",
    "\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: \n",
    "        break\n",
    "vc.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## **R2 - NOTA 8** \n",
    "Faz detecção de face em tempo real em vídeo ou webcam. Como resultado deve ter 2 janelas. A primeira janela com a imagem original e a segunda com filtro de sobreposição.\n",
    "Opções de filtros para aplicar sobre a face:\n",
    "- Na pasta img estão os exemplos de imagens que podem ser utilizadas tais como: dog, bigode, chapéu.\n",
    "Deve ser utilizado pelo menos uma das imagens para criar esse efeito. Usa o bigode OU(OR) chapéu OU(OR) …. \n",
    "Importante! A imagem de saída deve fazer sentido, ou seja, o chapéu na cabeça, o óculos sobre os olhos… um bigode na testa não faz sentido….Implementações extras, valem como nota extra..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glasses = cv2.imread(\"img/glasses.png\", -1)\n",
    "\n",
    "def overlay_filter(img):\n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img_gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray    = img_gray[y:y+h, x:x+w] \n",
    "        roi_color   = img[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eyes_classifier.detectMultiScale(roi_gray, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            roi_eyes = roi_gray[ey:ey+eh, ex:ex+ew]\n",
    "            resized_glasses = cv2.resize(glasses.copy(), (ew, eh))\n",
    "\n",
    "            gw, gh, gc = resized_glasses.shape\n",
    "            for i in range(0, gw):\n",
    "                for j in range(0, gh):\n",
    "                    if resized_glasses[i, j][3] != 0:\n",
    "                        roi_color[ey+i, ex+j] = resized_glasses[i, j]\n",
    "\n",
    "    return img   \n",
    "\n",
    "         \n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): \n",
    "    rval, frame = vc.read()\n",
    "\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"original\", frame)\n",
    "\n",
    "    img = overlay_filter(frame)\n",
    "    cv2.imshow(\"preview\", img)\n",
    "\n",
    "\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: \n",
    "        break\n",
    "vc.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## **R3 - NOTA 10**\n",
    "O aluno(a) pode alcançar a rubrica R3 ,com nota 10, de algumas formas diferente:\n",
    "- OU(OR) Faz o R1 E(AND) o R2 juntos dependendo do click do mouse. Realiza os dois processos de filtragem um de cada vez, para alternar entre os dois, o usuário faz um click com o mouse. O programa começa sem aplicar filtragem, quando é feito um click esquerdo com o mouse, realiza R1, no segundo click, realiza R2, no terceiro click volta para R1, e assim por diante...quando tem click do botão direito volta a imagem sem filtro. \n",
    "\n",
    "- OU(OR)  Faz o R1 com mais de 3 filtros diferentes, dependendo do click do mouse. Realiza os dois processos de filtragem um de cada vez, para alternar entre os três, o usuário faz um click com o mouse. O programa começa sem aplicar filtragem, quando é feito um click esquerdo com o mouse, aplicar filtro 1, no segundo click,  aplicar filtro 2, no terceiro click,  aplicar filtro 3, no quarto volta para filtro 1, e assim por diante...quando tem click do botão direito volta a imagem sem filtro.\n",
    "\n",
    "- OU(OR) Faz o R2 com mais de 3 filtros diferentes, dependendo do click do mouse. Realiza os dois processos de filtragem um de cada vez, para alternar entre os três, o usuário faz um click com o mouse. O programa começa sem aplicar filtragem, quando é feito um click esquerdo com o mouse, aplicar filtro 1, no segundo click,  aplicar filtro 2, no terceiro click,  aplicar filtro 3, no quarto volta para filtro 1, e assim por diante...quando tem click do botão direito volta a imagem sem filtro.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1º clique\n",
      "2º clique\n",
      "3º clique\n",
      "4º clique\n",
      "5º clique\n",
      "6º clique\n",
      "7º clique\n",
      "8º clique\n",
      "9º clique\n",
      "Clique no botão direito: filtro desativado\n",
      "10º clique\n"
     ]
    }
   ],
   "source": [
    "clicks = 1\n",
    "rbutton = False\n",
    "\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global clicks, rbutton\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        print(str('Clique no botão direito: filtro desativado'))\n",
    "        rbutton = True\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "         rbutton = False\n",
    "         print(str(clicks) + 'º clique')\n",
    "         clicks = clicks + 1\n",
    "\n",
    "\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): \n",
    "    rval, frame = vc.read()\n",
    "\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "\n",
    "    cv2.imshow(\"original\", frame)\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "\n",
    "    cv2.setMouseCallback('preview', mouse_click)\n",
    "    \n",
    "    if(rbutton or clicks == 1):\n",
    "        cv2.imshow(\"preview\", frame)\n",
    "    elif(clicks % 2 == 0):\n",
    "        cv2.imshow(\"preview\", linear_filter(frame))\n",
    "    else:\n",
    "        cv2.imshow(\"preview\", overlay_filter(frame))\n",
    "\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: \n",
    "        break\n",
    "    \n",
    "vc.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}